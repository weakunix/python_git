#Logic
A naive approach would be looping through all subsets of instructions and seeing which leads to tarx and tary because the order of instructions doesn't matter. Looking at the constraints, we can see that N is too large (2^40 is about 10^12). However, if N was 20, 2^N=10^6 which would run in time. This motivates a meet in the middle approach. We can consider the first half, then the second, and efficiently combine both results to find how many total subsets of instructions lead to (tarx, tary)

#Approach 1: Map (mapmethod.cpp)
After achieving the first half and second half, we can map each second half pair (x, y) in map. Each (x, y) would map to an array of size N/2, each storing how many subsets of instructions lead to (x, y) in the second half. The complexity for this would be O(2^(N/2)(logN+N)). Afterwards, for each pair (x, y) in the first half, we check for the complement (tarx - x, tary - y) in the map and if it exists, we loop through each index of the mapped vector and add to answer. This is O(2^(N/2)(N/2+N)). Why this doesn't run in time is a mystery to me, so it appears on revisit.txt

#Approach 2: Binary Search (binsearchmethod.cpp)
Instead of mapping the second half, we sort it by coordinates. For every pair (x, y) in the first half, the complement would be (tarx - x, tary - y). Sorting allows us to binary search on the second half, looking for all complement elements. Once we find the first one, we can continue to increase the index (in C++ I use an iterator) until the element is not equal to the complement. For each index, add the move count of the first and second pairs. This gives us a complexity of O(2^(N/2)(N/2)) for sorting and O(2^N(N/2)). This complexity is much to slow since we are performing 2^N (2^40 or 10^12) operations. Why is this? Because for every pair in the first half we may have to loop through the whole second half array in the most extreme case. This can be seen in test case 5 and 16 where the inputs are designed to create multiple ways of reaching one point in both the first and second halves. This motivates another approach

#Approach 3: Combination (RobotInstructions.cpp)
We combine both of the above. Instead of just sorting the second half, we sort the first half as well. This will group all the same (x, y) pairs in the first half together. If it's the first time seeing pair (x, y) in the first half, we create an array of size 21 (0-20 moves) and while we are computing the solution using the Binary Search approach, we can easily increment the move count array. If we see (x, y) again in the first half (which, since the first half is sorted, must be directly after a previous occurence) we can use the Map approach. Specifically, we will loop through the move count array and add it to the corresponding answer. This avoids a logarithmic factor each time since we don't use an ordered map. The total complexity would be O(2^(N/2)(N/2)) for sorting and I'm pretty shaky on the complexity for the algorithm. It seems similar to that of the Map approach which is why I'm pretty confused

#Approach 4: Hash Map
A hash map would remove the logarithmic factor in exchange for a high constant factor which should be much fastor. I didn't bother doing this approach since I didn't want to hash pairs but it seems doable. The complexity would be O(2^(N/2)N)
